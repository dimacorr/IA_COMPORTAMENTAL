# ğŸ” Proyecto: IA para DetecciÃ³n de Comportamiento Transaccional
Este proyecto implementa un modelo de Machine Learning para la detecciÃ³n de transacciones sospechosas en funciÃ³n 
del comportamiento del cliente. El objetivo es apoyar la detecciÃ³n temprana de fraude mediante el anÃ¡lisis de 
variables transaccionales relevantes.

## ğŸš€ DescripciÃ³n del Proyecto
El sistema toma datos transaccionales almacenados en PostgreSQL, los procesa y entrena un modelo de Machine Learning.
El modelo entrenado se guarda en un archivo con Pickle y luego se utiliza para predecir en tiempo real si una nueva 
transacciÃ³n es legÃ­tima o sospechosa.

####  âš ï¸ Nota importante:
* El modelo se aplica en tiempo real (predicciÃ³n sobre cada nueva transacciÃ³n).
* El modelo no se reentrena en tiempo real; el reentrenamiento se hace en procesos batch programados. 
* Para reentrenar en cada transacciÃ³n se necesitarÃ­a un esquema de online learning, lo cual no es el caso actual.

## ğŸ“Š Variables utilizadas en el modelo
* El modelo se alimenta de varias variables transaccionales clave:
* Monto de la transacciÃ³n (amount)
* Tipo de transacciÃ³n (tipo_transaccion)
* Hora de la transacciÃ³n (hora_decimal)
* Canal de la transacciÃ³n (channel_code)
* DÃ­a de la semana (dia_semana)
* CÃ³digo de monitoreo (motor_monitoreo_map)
* Tipo de alerta (alert_type)
* TelÃ©fono del cliente (client_mobilePhone)

ğŸ” Estas variables permiten identificar patrones de normalidad y anormalidad en las transacciones.

## ğŸ§® Modelo de Machine Learning
Se utiliza un `RandomForestClassifier`, un algoritmo basado en mÃºltiples Ã¡rboles de decisiÃ³n que:
* Promedia la decisiÃ³n de muchos Ã¡rboles â†’ mÃ¡s robustez.
* Tolera variables ruidosas mejor que otros modelos.
* Maneja bien datos categÃ³ricos y numÃ©ricos. 

##### Ventajas
* Buena precisiÃ³n.
* Resistente al overfitting en comparaciÃ³n con un solo Ã¡rbol.
* Capacidad de manejar muchas variables.

##### Limitaciones
* Si se incluyen muchas variables irrelevantes, puede introducir ruido.
* Modelos mÃ¡s simples (ej: RegresiÃ³n LogÃ­stica) pueden ser mÃ¡s interpretables.
* Modelos mÃ¡s avanzados (ej: XGBoost / LightGBM) pueden superar su precisiÃ³n si se configuran bien.

## âš ï¸ Overfitting (Sobreajuste)
El overfitting ocurre cuando el modelo "memoriza" los datos de entrenamiento en lugar de aprender patrones generales. </br>
Esto significa que:
* Funciona muy bien en el dataset de entrenamiento.
* Falla cuando llegan transacciones nuevas (datos que no habÃ­a visto antes).

#### CÃ³mo se mitiga:

* MÃ¡s datos de entrenamiento (mÃ¡s transacciones histÃ³ricas).
* RegularizaciÃ³n del modelo (limitar la profundidad de Ã¡rboles, nÃºmero de Ã¡rboles, etc.).
* SelecciÃ³n de variables â†’ usar solo las que realmente aportan.

## ğŸ› ï¸ VisiÃ³n TÃ©cnica (Flujo del Proyecto)
1. **Carga de datos** 
   * **Fuente:** base de datos Postgres (envios_cliente, transacciones). 
   * **Campos clave:** cliente, transacciÃ³n, hora de envÃ­o, canal, respuesta.
2. **Feature Engineering (ingenierÃ­a de caracterÃ­sticas)**
   * ConversiÃ³n de hora a valores numÃ©ricos. 
   * DÃ­as de la semana.
   * Retraso entre envÃ­o y respuesta.
   * Tasas de respuesta.
   * Flags de comportamiento inusual (ej. respuestas demasiado tardÃ­as). <br>
   ğŸ‘‰ Permite que el modelo capture patrones de riesgo de forma cuantitativa.
3. **Entrenamiento del modelo**
   * **Algoritmo:** `RandomForestClassifier` con balanceo de clases.
   * **Variable objetivo:**
     * `1` â†’ TransacciÃ³n sospechosa (alerta o declinada).
     * `0` â†’ TransacciÃ³n normal (confirmada).
4. **EvaluaciÃ³n del rendimiento**
   * **ROC AUC: ** mide la capacidad para distinguir fraude de no fraude
   * **Reporte de clasificaciÃ³n: ** precisiÃ³n, recall y F1-score.<br>
     ğŸ‘‰ MÃ©tricas que aseguran objetivamente la calidad del modelo.
5. **Persistencia del modelo**
   * El modelo entrenado se guarda en: `models/model.pkl.`
   * Se almacenan las features en: `models/features.pkl.`
   * Garantiza coherencia entre entrenamiento y predicciones en producciÃ³n.

#### ğŸ“Œ En resumen: El sistema transforma datos de comportamiento en seÃ±ales cuantitativas, entrena un modelo, lo 
valida con mÃ©tricas objetivas y lo despliega para predecir en tiempo real.

## ğŸ› ï¸ Prerrequisitos
Antes de ejecutar el proyecto, asegÃºrate de tener instalados los siguientes programas:
1. Python 3.10+ 
2. PostgreSQL 
3. pip y psql 
4. Git (opcional para clonar el repo)

#### ğŸ“Œ Importante: asegÃºrate de que Python y PostgreSQL estÃ©n en el PATH del sistema, sin importar si usas Windows, 
Linux o MacOS.

## ğŸš€ InstalaciÃ³n y requisitos
1. **Clonar el repositorio:**
```bash
  git clone https://github.com/tu-repo/IA_COMPORTAMENTAL.git
  cd IA_COMPORTAMENTAL
```

2. **Crear entorno virtual:**
```powershell
 python -m venv .venv
 .venv\Scripts\activate      # Windows
 # source .venv/bin/activate # Linux/Mac
```

3. **Instalar dependencias:**
```powershell
 pip install -r requirements.txt
```

4. **Crear base de datos y tablas:**
```bash
 psql -U <usuario> -d <nombre_base_datos> -f sql/schema.sql
```

#### ğŸ“Œ Nota: Antes de ejecutar el proyecto, asegÃºrate de tener PostgreSQL corriendo localmente, 
de crear la base de datos, las tablas necesarias, y ejecutar el script SQL incluido

5. **Configurar `.env:`**
```powershell
 DATABASE_URL=postgresql://user:password@host:port/db
 MODEL_DIR=models
 THRESHOLD=0.7
```

5. **Entrenar modelo (opcional):**
```powershell  
 python -m scripts.train
```

6. **Levantar API con FastAPI:**  
```bash
 uvicorn main:app --reload
```

DocumentaciÃ³n interactiva:
```bash
 POST http://127.0.0.1:8000/predict
```

## ğŸ“¦ Estructura del proyecto
```powershell
ia_comportamental/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ main.py                # Entrypoint FastAPI
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model.pkl
â”‚   â””â”€â”€ features.pkl
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train.py           # Script para entrenar
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ schema.sql
â””â”€â”€ src/
    â”œâ”€â”€ domain/
    â”‚   â”œâ”€â”€ entities.py
    â”‚   â”œâ”€â”€ behavior.py
    â”‚   â””â”€â”€ services.py    # Interfaces como PredictorService
    â”œâ”€â”€ usecases/
    â”‚   â”œâ”€â”€ train_model.py
    â”‚   â”œâ”€â”€ schemas.py
    â”‚   â””â”€â”€ predict_response.py
    â”œâ”€â”€ infra/
    â”‚   â”œâ”€â”€ config.py
    â”‚   â”œâ”€â”€ repository_postgres.py
    â”‚   â””â”€â”€ models_store.py
    â”œâ”€â”€ features/
    â”‚   â””â”€â”€ feature_engineering.py  # FeatureEngineering
    â”œâ”€â”€ ml/
    â”‚   â””â”€â”€ inference.py
    â”œâ”€â”€ entrypoints/
    â”‚   â””â”€â”€ api.py
    â””â”€â”€ tests/
        â”œâ”€â”€ test_feature_engineering.py
        â””â”€â”€ test_predict_response.py
```

## ğŸ§ª Ejemplo de inferencia

Payload de prueba (No Fraude):
```powershell
{
  "client_id": "302",
  "amount": 1000.00,
  "tipo_transaccion": "compra",
  "channel_code": "WEB",
  "motor_monitoreo_map": "normal",
  "alert_type": "compra_estandar",
  "dia_semana": 2,
  "client_mobilePhone": "3202222222",
  "response_text": "SÃ­",
  "timestamp": "2025-08-25T10:00:00",
  "total_sent": 1,
  "response_rate": 1.0,
  "mean_delay": 0
}
```

Respuesta esperada:
```powershell
{
    "prediction": "no_fraude",
    "probability": 0.51,
    "threshold_used": 0.7,
    "behavior_flags": {
        "unusual_response_rate": false,
        "unusual_mean_delay": false
    }
}
```

Payload de prueba (Fraude):
```powershell
{
  "client_id": "301",
  "amount": 750000.00,
  "tipo_transaccion": "compra",
  "channel_code": "WEB",
  "motor_monitoreo_map": "sospechoso",
  "alert_type": "compra_monto_alto",
  "dia_semana": 6,
  "client_mobilePhone": "3211111111",
  "response_text": "No",
  "timestamp": "2025-08-27T14:30:00",
  "total_sent": 15,
  "response_rate": 0.1,
  "mean_delay": 300
}
```

Esperado en respuesta:

```powershell
{
    "prediction": "fraude",
    "probability": 0.07,
    "threshold_used": 0.7,
    "behavior_flags": {
        "unusual_response_rate": true,
        "unusual_mean_delay": true
    }
}
```

## ğŸ“– Glosario de tÃ©rminos clave
 * **Machine Learning:** Rama de la inteligencia artificial que permite a los sistemas aprender de los datos y hacer 
   predicciones sin ser programados explÃ­citamente. En este proyecto se utiliza para detectar patrones de 
   comportamiento y posibles fraudes.
 * **Feature Engineering:** Proceso de transformaciÃ³n de los datos crudos en variables (features) Ãºtiles para el 
   entrenamiento del modelo. AquÃ­ se generan seÃ±ales cuantitativas como `hour`, `weekday`, `response_rate`, etc.
 * **PredicciÃ³n:** Proceso en el que el modelo entrenado clasifica nuevos datos para determinar si corresponden a 
   comportamiento normal o posible fraude.
 * **RandomForestClassifier:** Algoritmo de clasificaciÃ³n basado en mÃºltiples Ã¡rboles de decisiÃ³n, 
   usado en este proyecto como modelo principal por su robustez y capacidad de manejar desbalance de clases.
 * **ROC AUC (Receiver Operating Characteristic - Area Under Curve):** MÃ©trica que mide la capacidad del modelo para 
   distinguir entre clases (fraude vs. no fraude). Un valor cercano a 1 indica un mejor desempeÃ±o.
 * **PrecisiÃ³n (Precision):** ProporciÃ³n de casos predichos como positivos que realmente lo son. 
   EvalÃºa quÃ© tan â€œexactasâ€ son las alertas generadas por el modelo.
 * **Recall (Sensibilidad o Exhaustividad):** ProporciÃ³n de positivos reales que fueron correctamente detectados 
   por el modelo. Mide la capacidad de detectar fraudes sin que se escapen.
 * **F1-Score:**  MÃ©trica que combina precisiÃ³n y recall en un solo valor armÃ³nico. Es Ãºtil cuando hay desbalance 
   en las clases (fraude vs. no fraude).
   ğŸ‘‰ Un F1-score alto significa que el modelo detecta la mayorÃ­a de fraudes sin generar demasiados falsos positivos.
 * **Threshold (Umbral de decisiÃ³n):** Valor de corte de probabilidad para clasificar si una transacciÃ³n es fraude (1) 
   o no (0). Un umbral mÃ¡s bajo detecta mÃ¡s fraudes, pero aumenta falsos positivos.
 * **Arquitectura Limpia (Clean Architecture):** PatrÃ³n de diseÃ±o que organiza el proyecto en capas separando lÃ³gica de 
   negocio (domain, usecases) de la infraestructura y adaptadores. Permite mayor mantenibilidad y escalabilidad.

## â“ ExplicaciÃ³n del Modelo (FAQ)
1. **Â¿QuÃ© pasa si agrego variables no relevantes o muy relevantes?**
* No relevantes â†’ generan ruido, pueden bajar la precisiÃ³n del modelo.
* Relevantes â†’ mejoran el desempeÃ±o porque aportan mÃ¡s seÃ±ales Ãºtiles.
2. **Â¿CÃ³mo puedo jugar con las variables?**
* Agregar o quitar variables en feature_engineering.py.
* Probar diferentes combinaciones de features.
* Evaluar importancia de variables con el propio Random Forest.
3. **Â¿El modelo mejora con mÃ¡s informaciÃ³n?**
SÃ­. MÃ¡s registros histÃ³ricos permiten al modelo aprender mejor, generalizar y reducir sesgos.
4. **Â¿CÃ³mo se estandarizan los datos?**
En este proyecto no aplicamos normalizaciÃ³n numÃ©rica, ya que el algoritmo Random Forest no depende de la escala de los datos.
Lo que sÃ­ realizamos es feature engineering y preprocesamiento, transformando variables categÃ³ricas a numÃ©ricas, 
generando nuevas variables derivadas y limpiando los datos antes del entrenamiento.

## âœ… Notas finales
 * Activa el entorno virtual antes de usar scripts o FastAPI. 
 * Ajusta el `.env` segÃºn tu configuraciÃ³n. 
 * Usa pytest src/tests/ para verificar que todo funciona.